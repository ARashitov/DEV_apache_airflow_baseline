{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "secondary-engagement",
   "metadata": {},
   "source": [
    "# About\n",
    "* **Author**: Adil Rashitov\n",
    "* **Created at**: 21.06.2021\n",
    "* **Goal**: Prepare parameters for web scrappers [118 direct](http://www.118.direct)\n",
    "* **Deliverable**: parameters in postgresSQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "material-freedom",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports / Configs / Global vars\n",
    "\n",
    "# Import of native python tools\n",
    "import os\n",
    "import json\n",
    "from functools import reduce\n",
    "\n",
    "# Import of base ML stack libs\n",
    "import numpy as np\n",
    "import sklearn as sc\n",
    "\n",
    "# Multiprocessing for Mac / Linux\n",
    "import platform\n",
    "platform.system()\n",
    "if platform.system() == 'Darwin':\n",
    "    from multiprocess import Pool\n",
    "else:\n",
    "    from multiprocessing import Pool\n",
    "\n",
    "# Visualization libraries\n",
    "import plotly.express as px\n",
    "\n",
    "# Logging configuraiton\n",
    "import logging\n",
    "logging.basicConfig(format='[ %(asctime)s ][ %(levelname)s ]: %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p')\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Ipython configs\n",
    "from IPython.core.display import display, HTML\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "# Pandas configs\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "pd.options.display.max_rows = 350\n",
    "pd.options.display.max_columns = 250\n",
    "\n",
    "# Jupyter configs\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "\n",
    "# GLOBAL VARS\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('./.rds_endpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-deployment",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "1. Web scrapping of businesses categories\n",
    "2. Web scrapping of locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86def319",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_CATEGORIES = '/WORKDIR/data/sources/bussiness_categories_to_extract/categories.csv.zip'\n",
    "S_LOCATIONS = '/WORKDIR/data/sources/locations_to_extract/locations.csv.zip'\n",
    "\n",
    "\n",
    "categs = pd.read_csv(S_CATEGORIES)\n",
    "locs = pd.read_csv(S_LOCATIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3459a0",
   "metadata": {},
   "source": [
    "# Main\n",
    "\n",
    "1. Generation of base urls for search\n",
    "2. Extraction amount of pages from each category\n",
    "3. Generation url with page specified to get all results\n",
    "4. Export search parameters to database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27acd4c5",
   "metadata": {},
   "source": [
    "### 1. Generation of base urls for search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bad40af1",
   "metadata": {
    "code_folding": [
     0,
     5,
     14,
     22
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pandas/core/frame.py:1549: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>what</th>\n",
       "      <th>where</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abattoirs</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>http://www.118.direct/listing/search?what=Abat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Access Control Systems</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>http://www.118.direct/listing/search?what=Acce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Access Equipment</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>http://www.118.direct/listing/search?what=Acce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accountants</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>http://www.118.direct/listing/search?what=Acco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accounting &amp; Bookkeeping Services</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>http://www.118.direct/listing/search?what=Acco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                what       where  \\\n",
       "0                          Abattoirs  Manchester   \n",
       "1             Access Control Systems  Manchester   \n",
       "2                   Access Equipment  Manchester   \n",
       "3                        Accountants  Manchester   \n",
       "4  Accounting & Bookkeeping Services  Manchester   \n",
       "\n",
       "                                                 url  \n",
       "0  http://www.118.direct/listing/search?what=Abat...  \n",
       "1  http://www.118.direct/listing/search?what=Acce...  \n",
       "2  http://www.118.direct/listing/search?what=Acce...  \n",
       "3  http://www.118.direct/listing/search?what=Acco...  \n",
       "4  http://www.118.direct/listing/search?what=Acco...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generation of URLS\n",
    "def container(func, kwargs):\n",
    "    return func(**kwargs)\n",
    "\n",
    "\n",
    "def generate_url(what: str, where: str) -> str:\n",
    "    \"\"\"\n",
    "        Arguments:\n",
    "            * what (str): business category name\n",
    "            * where (str): location\n",
    "    \"\"\"\n",
    "    return f\"http://www.118.direct/listing/search?what={what}&where={where}\"\n",
    "\n",
    "\n",
    "def generate_dataframe_for_region(bussines_categs, loc):\n",
    "    return pd.DataFrame({\n",
    "        'what': bussines_categs,\n",
    "        'where': loc\n",
    "    })\n",
    "\n",
    "\n",
    "search_params = generate_dataframe_for_region(categs['business_category'], locs.values[0][0])\n",
    "search_params['url'] = \\\n",
    "    list(map(container,\n",
    "             [generate_url]*search_params.shape[0],\n",
    "             search_params.to_dict('record')))\n",
    "\n",
    "search_params.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2966dece",
   "metadata": {},
   "source": [
    "### 2. Extraction amount of pages from each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62029ece",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def extract_n_entities(arg: dict) -> dict:\n",
    "    \"\"\"\n",
    "        Gets amount of entities available\n",
    "        for web scrapping at particular location.\n",
    "        \n",
    "        Arguments:\n",
    "            * arg (dict): request arguments\n",
    "                * `url`: url of specified category and locations\n",
    "    \"\"\"\n",
    "    time.sleep(np.random.normal(1, 0.2))\n",
    "\n",
    "    html_text = requests.get(arg['url']).text\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "        n_entities = soup \\\n",
    "            .find_all(\"div\", class_=\"resultInfoBlock\")[0] \\\n",
    "            .contents[0]\n",
    "\n",
    "        n_entities = re.findall(r'\\d+', n_entities.split('of ')[1])\n",
    "        arg['n_entities'] = int(n_entities[0])\n",
    "\n",
    "    except Exception as exc:\n",
    "        logging.error(f\"{arg}: {str(exc)}\")\n",
    "\n",
    "    return arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "172c1d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /WORKDIR/data/intermediate/request_params_with_n_entities_in_category/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f79f7c12",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 06/25/2021 03:05:59 PM ][ INFO ]: File already exsits...\n",
      "[ 06/25/2021 03:05:59 PM ][ INFO ]: Reading from /WORKDIR//data/intermediate/request_params_with_n_entities_in_category/parameters.csv.zip...\n"
     ]
    }
   ],
   "source": [
    "# N entites in category\n",
    "STEP2_TARGET_FILE = '/WORKDIR//data/intermediate/request_params_with_n_entities_in_category/parameters.csv.zip'\n",
    "\n",
    "if not os.path.isfile(STEP2_TARGET_FILE):\n",
    "    logging.info(\"Sending requests to extract n entities available\")\n",
    "    with Pool(2) as pool:\n",
    "        search_params = pool.starmap(extract_n_entities,\n",
    "                                     zip(search_params.to_dict('record')))\n",
    "    del pool\n",
    "    search_params = pd.DataFrame(search_params).reset_index(drop=True)\n",
    "    \n",
    "    search_params.to_csv('/WORKDIR/data/intermediate/request_params_with_n_entities_in_category/parameters.csv.zip', index=False, compression='zip')\n",
    "else:\n",
    "    logging.info(\"File already exsits...\")\n",
    "    logging.info(f\"Reading from {STEP2_TARGET_FILE}...\")\n",
    "    search_params = pd.read_csv(STEP2_TARGET_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5c652d",
   "metadata": {},
   "source": [
    "### 3. Generation url with page specified to get all results\n",
    "\n",
    "Each page has 15 entities, so we need to map range of entites to page to know page urls\n",
    "\n",
    "* **input format**: `http://www.118.direct/listing/search?what=<what>&where=<where>`\n",
    "* **output format**:`http://www.118.direct/listing/search?what=<what>&where=<where>&page=<page>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a89f622b",
   "metadata": {
    "code_folding": [
     0,
     10,
     23
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 06/25/2021 03:06:06 PM ][ INFO ]: N urls at input: 1151\n",
      "[ 06/25/2021 03:06:06 PM ][ INFO ]: N urls at output: 6638\n"
     ]
    }
   ],
   "source": [
    "# Generation url with page parameter\n",
    "n_entities_in_list = 15\n",
    "\n",
    "# 1. Extraction n pages for each category\n",
    "n_int_pages = search_params['n_entities'] // n_entities_in_list\n",
    "is_div_fractional = (search_params['n_entities'] % n_entities_in_list) > 0\n",
    "search_params['n_pages'] = n_int_pages + is_div_fractional\n",
    "\n",
    "\n",
    "# 2. Generation urls for pages\n",
    "def generate_url_with_pages(arg):\n",
    "    return pd.DataFrame({\n",
    "        **arg,\n",
    "        'page': list(range(1, arg['n_pages']+1, 1))\n",
    "    })\n",
    "\n",
    "search_params_with_page = list(map(\n",
    "    generate_url_with_pages,\n",
    "    search_params.to_dict('records')\n",
    "))\n",
    "\n",
    "logging.info(f\"N urls at input: {search_params.shape[0]}\")\n",
    "search_params_with_page = pd.concat(search_params_with_page).reset_index(drop=True)\n",
    "col_rename_params = {\n",
    "    'url': 'base_url',\n",
    "    'n_entities': 'n_entities_at_category_at_location',\n",
    "    'n_pages': 'n_pages_at_category_at_location',\n",
    "    'page': 'page'\n",
    "}\n",
    "search_params_with_page = search_params_with_page.rename(columns=col_rename_params)\n",
    "logging.info(f\"N urls at output: {search_params_with_page.shape[0]}\")\n",
    "\n",
    "# 3. Building full url\n",
    "search_params_with_page['full_url'] = search_params_with_page['base_url'] + \"&page=\" + search_params_with_page['page'].astype(str)\n",
    "\n",
    "\n",
    "# 4. Columns selection\n",
    "search_params_with_page['scrapping_parameter_id'] = list(search_params_with_page.index)\n",
    "cols = [\n",
    "    'scrapping_parameter_id', 'what', 'where', 'n_entities_at_category_at_location',\n",
    "    'n_pages_at_category_at_location', 'page', 'base_url', 'full_url'\n",
    "]\n",
    "search_params_with_page = search_params_with_page[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d028dbc",
   "metadata": {},
   "source": [
    "### 4. Export search parameters to database\n",
    "\n",
    "Export request parameters to rds database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f6bb1bb",
   "metadata": {
    "code_folding": [
     7
    ]
   },
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "\n",
    "TABLE_NAME=\"WEB_SCRAPPER_PARAMETERS\"\n",
    "\n",
    "RDS_ENGINE = sqlalchemy.create_engine(os.environ['RDS_ENDPOINT'])\n",
    "\n",
    "\n",
    "WEB_SCRAPPER_PARAMETERS_SCHEMA = {\n",
    "    'scrapping_parameter_id': sqlalchemy.types.Integer,\n",
    "    'what': sqlalchemy.types.String,\n",
    "    'where': sqlalchemy.types.String,\n",
    "    'n_entities_at_category_at_location': sqlalchemy.types.SmallInteger,\n",
    "    'n_pages_at_category_at_location': sqlalchemy.types.SmallInteger,\n",
    "    'page': sqlalchemy.types.SmallInteger,\n",
    "    'base_url': sqlalchemy.types.String,\n",
    "    'full_url': sqlalchemy.types.String\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d011b3a0",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "search_params_with_page.to_sql(\n",
    "    name=TABLE_NAME,\n",
    "    con=RDS_ENGINE,\n",
    "    schema=\"public\",\n",
    "    if_exists=\"replace\",\n",
    "    index=False,\n",
    "    dtype=WEB_SCRAPPER_PARAMETERS_SCHEMA,\n",
    "    method=\"multi\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
